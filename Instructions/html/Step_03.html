
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Step 3: Detecting Design Errors</title><meta name="generator" content="MATLAB 9.5"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2018-10-31"><meta name="DC.source" content="Step_03.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:14px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:2.0em; color:#000077; line-height:150%; font-weight:bold; text-align:center }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.6em; color:#444444; font-weight:bold; font-style:italic; text-align:left; vertical-align:bottom; line-height:200%; border-top:2px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#555555; font-style:italic; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px;} 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Step 3: Detecting Design Errors</h1><!--introduction--><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Introduction</a></li><li><a href="#2">Verification and Validation Tools Used</a></li><li><a href="#3">Running Dead Logic Detection on the Model</a></li><li><a href="#4">Checking Design Changes for Dead Logic</a></li><li><a href="#5">Running Divide by Zero Detection on the Model</a></li><li><a href="#6">Automating Design Error Detection Checks</a></li><li><a href="#7">Summary</a></li></ul></div><h2>Introduction<a name="1"></a></h2><p><img vspace="5" hspace="5" src="Step_03_CruiseControl_WhatNow.png" alt=""> </p><p>There are many different ways to perform testing in Simulink. Traditionally, verification involves the user creating a set of test vectors based on certain requirements. The user can also create a set of expected outputs matching the giving inputs, or visually analyze the simulation making sure the behavior is as expected. The type of test vector created can be either functional, or based on certain robustness criteria or standards. With this method, the quality of the test is entirely based on the quality of the input vectors and being able to capture or reproduce a real world scenario as closely as possible. This topic is covered in <b>Step 4:  Testing by Simulation</b>.</p><p>One of the benefits of Model-Based Design is the ability to apply other &#8220;non-simulation&#8221; techniques to your model. These formal techniques are most beneficial when you are working with logic-intensive models. In this section, we will use <b>Simulink Design Verifier</b> to formally analyze our model for us to check if there are any unreachable states or transitions and if there are any divide by zero design errors.  The recommendation is to run these design error checks before executing the simulation based tests to catch errors early and have a more efficient testing workflow.</p><p>There are three main functions <b>Simulink Design Verifier</b>:</p><div><ol><li><b>Design Error Detection</b>:  Focus of this step, finds hard to find design errors including dead logic, divide by zero, overflow and out of bound array access</li><li><b>Test Generation</b>: Focus of <b>Step 5:  Test Case Generation</b>, generate test cases based on model objectives and/or coverage objectives to augment functional test cases</li><li><b>Property Proving</b>:  Focus of <b>Step 8:  Property Proving</b>, model the expected behavior and prove the implementation will always meet requirements</li></ol></div><p><img vspace="5" hspace="5" src="Step_04_SLDVOverview.png" alt=""> </p><p>In addition to formal techniques for model checking, there are formal techniques for code checking.  These methods are similar to the checks for the model and we will will perform these checks on the associated code for an s-function block in the model.  We will be using Polyspace Bug Finder to analyze the code for run-time errors including dead code, divide by zero, overflow and out of bound array access.</p><h2>Verification and Validation Tools Used<a name="2"></a></h2><div><ul><li>Simulink Design Verifier</li><li>Polyspace Bug Finder</li></ul></div><h2>Running Dead Logic Detection on the Model<a name="3"></a></h2><p>In this step, we are going to use <b>Simulink Design Verifier</b> to analyze our model. Our goal is find dead logic, meaning logic that cannot be true and false based on the input ranges and data flow analysis. We can also analyze our model for design errors like integer overflows, division by zero and out of bound array access.</p><p>We will be using <b>Design Error Detection</b> to check each design iteration. In this section we will first analyze our design from the ad-hoc testing and then in a later section iteratively change the design based on feedback from design reviews and field testing.</p><p><b><i>Simulink Design Verifer uses formal methods which means that the analysis is "exhaustive" compared to simulation-based testing which is "non-exhaustive".</i></b></p><p>We will be using the "CruiseControl" model with the design changes from the ad-hoc testing.</p><p>To perform the dead logic analysis, do the following:</p><p>1.  Open "CruiseControl.slx" &#8211; <b><a href="matlab:B1_DED_IterDesign">click here</a></b>.</p><p>2.  Make the menu selection <b>Analysis/Design Verifier/Options</b>.</p><p><img vspace="5" hspace="5" src="Step_03_DV_OptMenu.png" alt=""> </p><p>3.  In the <b>Configuration Parameters</b> dialog, navigate to ... <b>Design Error Detection</b>, check <b>Dead logic</b>, check <b>Identify active logic</b> and select <b>OK</b>.</p><p><img vspace="5" hspace="5" src="Step_03_DV_OptUI.png" alt=""> </p><p>4.  To perform the analysis, make the menu selection <b>Analysis/Design Verifier/Detect Design Errors/Model</b>.</p><p>Once completed the results window will appear. Near the top of the results window, there is information that tells the user the current status.  In this case, the model has total of (74) objectives.</p><p><img vspace="5" hspace="5" src="Step_03_DV_Results1.png" alt=""> </p><p>For each decision or transition, there are two objectives: one for a true result and one for a false result.  There are also two corresponding objectives for each condition.   As an example, a single condition decision would only have (2) objectives but a double condition decision would have (6) objectives:</p><div><ul><li>(2) for the decision and</li><li>(4) for the two conditions</li></ul></div><p><b>The analysis will shows there are no falsified objectives.</b></p><p>This means all of the T/F decision and condition objectives <b>can</b> be achieved based on the input ranges and data flow analysis.  This is a static test and should not be confused with coverage analysis which indicates whether each objective has been achieved through a dynamic test or a simulation test using a set of input vectors.  Below we will show how to get coverage based on the generated test cases from the analysis.</p><p><b>It is recommended to run Design Error Detection for Dead Logic before simulation based testing and before checking in design changes.</b></p><p>5. To review the results on the model, select "Highlight analysis results on the model" in the results summary window.  Select transitions in the chart to understand what objectives are being analyzed.</p><p>In the example below, the exit transition "[Brake  Speed&gt;maxtspeed  Speed&lt;mintspeed]" was analyzed for (2) Decision objectives and (6) Condition Objectives.</p><p><img vspace="5" hspace="5" src="Step_03_DV_ResultsColors1.png" alt=""> </p><p>6.  For more details on the results open the report by selecting the "Detailed analysis report: (HTML)" link in the results summary window.</p><p>To get help with interpreting the <b>Design Verifier</b> results in the report - <b><a href="matlab:web(fullfile(docroot,'sldv/ug/simulink-design-verifier-reports.html'))">click here</a></b>.</p><p>The results show all objectives as "Active Logic - needs simulation" which means further simulation is needed to confirm the "active logic" status. <b>Design Verifier</b> has generated test cases and created a test harness to facilitate the confirmation of the "active logic" status.</p><p>7. To open the harness select "Open harness model" in the results summary window.</p><p><img vspace="5" hspace="5" src="Step_03_DV_ResultsHarness1.png" alt=""> </p><p>8. Open the "Signal Builder" block in the harness and press the "Run All" button.</p><p><img vspace="5" hspace="5" src="Step_03_DV_ResultsSigBldr1.png" alt=""> </p><p>Once all the test cases have been executed a "Coverage Results" window will popup to show the coverage results for the harness.</p><p><img vspace="5" hspace="5" src="Step_03_DV_ResultsCoverage1.png" alt=""> </p><p>These are coverage results for running all the generated test cases. Notice the "CruiseControl_harness" has 100% coverage which confirms the "active logic" status for all the objectives.  The generated test cases are structural and not functional test cases, meaning they are not based on requirements or expected behavior.  This confirms it is possible to create requirements based test cases to completely cover the model if the requirements and implementation match.  More on this topic is covered in "Step 4:  Testing by Simulation".</p><p>9.  Select "Highlight model with coverage results" to show all transitions are fully covered.</p><p><img vspace="5" hspace="5" src="Step_03_DV_HighlightCoverage1.png" alt=""> </p><p>We now have a good design that has passed ad-hoc testing and has no dead logic.</p><h2>Checking Design Changes for Dead Logic<a name="4"></a></h2><p>In the previous section we showed our refined model from the ad-hoc testing had no "dead logic" or all "active logic".  In this section we will go through a few design iterations and analyze each change for "dead logic" using <b>Design Error Detection</b> function as we did in the previous section.</p><p>From a design review it was pointed out that the early ad-hoc testing and static analysis were performed with nominal calibration values.  It was recommended to perform the ad-hoc testing and static analysis at the limits of the calibration values.  Specifically test the design with the maximum "holdrate" of (10) and the maximum "incdec" of (2).  First an "incdec" value of (2) was used; the design passed the ad-hoc testing and the static analysis with no "dead logic".  Next a "holdrate" value of (10) was used: the design passed the ad-hoc testing and the static analysis found (10) objectives were "dead logic".  Let's modify the "holdrate" value to (10) and run <b>Design Error Detection</b> to investigate the results.</p><p>1.  If not open, open "CruiseControl.slx" &#8211; <b><a href="matlab:B1_DED_IterDesign">click here</a></b>.</p><p>2.  In the command window, execute "holdrate.Value = 10"</p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter1_holdrate10.png" alt=""> </p><p>3.  Perform <b>Design Error Detection</b> on the model</p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter1_Results.png" alt=""> </p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter1_Colors0.png" alt=""> </p><p>4.  Analyze the transitions with "dead logic"</p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter1_Colors1.png" alt=""> </p><div><ul><li>Transition "[after(10*incdec/holdrate,tick)]" can never be false.  The transition expression "10*incdec/holdrate" evaluates to (1).  The tick value is always greater than or equal to (1) so the transition will always be valid (or executed).</li></ul></div><p><img vspace="5" hspace="5" src="Step_03_DV_Iter1_Colors2.png" alt=""> </p><div><ul><li>Transition "hasChangedTo(AccelResSw,false)  tspeed&gt;maxtspeed" can never be false.  The transition is only tested after the first transition "[AccelResSw]" is false so the condition "hasChangedTo(AccelResSw,false)" will always be true.  The overall decision will always be true which makes the second condition of an or decision "dead logic".</li></ul></div><p>It appears the design has logic errors when we have a "holdrate" of (10). But we know that with a "holdrate" of (5) the design has no "dead logic". Is there a way to test the design with multiple values of the "holdrate" that would show the design has no "dead logic"?  Yes!  <b>Design Verfier</b> provides a pane to enter a range of parameters to be used in the static analysis.</p><p>5.  Open <b>Design Verifier</b> and navigate to the "Parameters" section. Configure the "Parameters" to use the full range of "[0 10]".  This can be automated by selecting <b>Find in Model</b> and enabling the <b>Use</b> of the "holdrate" parameter.</p><p><img vspace="5" hspace="5" src="Step_03_DV_ParamTable.png" alt=""> </p><p>6.  Run <b>Design Error Detection</b> on the model</p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter1_Results2.png" alt=""> </p><p>Using the parameter range, <b>Design Error Detection</b> now shows our design has no "dead logic".</p><p>The model was then analyzed in a design review meeting.  From the design review it was highly recommended to change the execution order of the exit transition and hold transition so the exit condition based on the maximum safe speed was executed first.</p><p>7.  In the model change the execution order so the exit condition based on target speed "tspeed" from the "Accel" and "Coast" state were executed first.</p><p><img vspace="5" hspace="5" src="Step_03_DV_IterModel1.png" alt=""> </p><p>8.  Run <b>Design Error Detection</b> on the model</p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter2_Results.png" alt=""> </p><p>9.  Analyze the transitions with "dead logic"</p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter2_Colors1.png" alt=""> </p><div><ul><li>Transition "[AccelResSw]" can never be false.  This transition is now tested after the first transition condition "hasChangedTo(AccelResSw,false)" has been evaluated.  If "hasChangedTo(AccelResSw,false)" is false then "[AccelResSw]" has to be true making the false objective for "[AccelResSw]" not achievable.</li></ul></div><p>10.  Remove the "[AccelResSw]" transition and the corresponding "[CoastSetSw]" transition.</p><p>11. Run <b>Design Error Detection</b> on the model</p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter1_Results2.png" alt=""> </p><p>Once again we have been able to make design changes and use <b>Design Error Detection</b> to aid us in achieving a robust design with no "dead logic".</p><p>After another design review, it was recommended to include limit checks on the speed "Accel" and "Coast" calculation to improve the robustness with respect to having the target speed go beyond the safety limits "maxtspeed" and "mintspeed".</p><p>12.  Modify the model to include these limit checks on the target speed or load a modifed model &#8211; <b><a href="matlab:B1_DED_IterDesign3">click here</a></b>.</p><p><img vspace="5" hspace="5" src="Step_03_DV_IterModel3.png" alt=""> </p><p>13.  Run <b>Design Error Detection</b> on the model</p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter3_Results.png" alt=""> </p><p>14.  Analyze the transitions with "dead logic"</p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter3_Colors1.png" alt=""> </p><div><ul><li>Transition condition "tspeed &gt; maxtspeed" can never be true due to the limit check in the "Accel" state.  While looking at this condition, is there a design logic error?  Yes!  The transition condition should be "tspeed <b>&gt;=</b> maxtspeed".</li></ul></div><div><ul><li>The corresponding transition "tspeed &lt; mintspeed" for the "Coast" state shows "dead logic" and needs to be modified to "tspeed &lt;= mintspeed".</li></ul></div><p>15.  Modify the model to include these logic operator changes.</p><p><img vspace="5" hspace="5" src="Step_03_DV_IterModel3_2.png" alt=""> </p><p>16.  Run <b>Design Error Detection</b> on the model</p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter3_Results2.png" alt=""> </p><p>It might be a suprise that the results show (2) falsified objectives.</p><p>17.  Analyze the transitions with "dead logic"</p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter3_Colors2.png" alt=""> </p><p>The "tspeed" limit transition "[tspeed &gt; maxtspeed]" true objective was found to be "dead logic".  The modified exit condition "tspeed &gt;= maxtspeed" will exit the state before "tspeed" can be increased beyond "maxtspeed".  Based on this result, maybe the recommended safety design change was not needed.  With further study, we realize the value of "incdec" was (1) for the static analysis but in practice it can have a value of (1) or (2).  For an "incdec" value of (2) it appears the limit check is necessary.  Let's include the range of "incdec" in the analysis.</p><p>18.  Modify the <b>Design Verifier</b> settings to include the range of "incdec"</p><p><img vspace="5" hspace="5" src="Step_03_DV_ParamTable2.png" alt=""> </p><p>19.  Run <b>Design Error Detection</b> on the model</p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter3_Results3.png" alt=""> </p><p>20.  In the model select the transition "[tspeed &gt; maxtspeed]" to update the results window.  To retrieve the "Test #", select <b>View test case</b> to open up the signal builder dialog with "Test Case 9" displayed.</p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter3_Transition.png" alt=""> </p><p>21.  Use the test # (9) to navigate to the "Test Case 9" in the report that satisfies the true objective for the "[tspeed &gt; maxtspeed]" transition in the limit check.</p><p><img vspace="5" hspace="5" src="Step_03_DV_Iter3_TestCaseRpt3.png" alt=""> </p><p>Notice the test case uses a value of (2) for "incdec".</p><p>We have gained an insight into our design by iteratively checking our design and interpreting the results.</p><h2>Running Divide by Zero Detection on the Model<a name="5"></a></h2><p>Another feature of <b>Design Error Detection</b> is the ability to analyze the model for calculations that result in a divide by zero. Calibrations typically have a range of values that are permissible within specified limits. As we did in the previous section, we will use the parameter table in the <b>Simulink Design Verifier</b> settings to perform the analysis over a range of values.  To perform the "divide by zero" analysis, do the following:</p><p>1.  Open the "CruiseControl.slx" based on the "dead logic" work &#8211; <b><a href="matlab:B2_DED_DivideByZero;">click here</a></b>.</p><p>2.  In the <b>Design Verifier</b> settings, check the parameter table has been enabled with "holdrate" and "incdec" enabled.  These are the same settings from the final "dead logic" analysis perform in the previous section.</p><p><img vspace="5" hspace="5" src="Step_03_DV_ParamTable2.png" alt=""> </p><p>2.  For this analysis, configure <b>Design Error Detection</b> to check for <b>Division by zero</b>.</p><p><img vspace="5" hspace="5" src="Step_03_DV_CfgDivByZero.png" alt=""> </p><p>3.  Make the menu selection <b>Analysis/Design Verifier/Detect Design Errors/Model</b> to perform the analysis on the model</p><p><img vspace="5" hspace="5" src="Step_03_DV_DivByZeroResult1.png" alt=""> </p><p>Let&#8217;s take a look at the results and see what might be causing the error.</p><p>4.  Open the report to help us debug the divide by zero issue.</p><p><img vspace="5" hspace="5" src="Step_03_DV_DivByZeroReport.png" alt=""> </p><p>Since the analysis included the use of a parameter table to specify a range of parameter values that were part of the analysis.  Navigate in the report to the "Parameter Constraints" section to verify the range that was used in the analysis.  Next look at the generated test cases, noting the parameter values of (0) for the "holdrate".</p><p>5.  Using the generated harness model, run "Test Case 1" to debug the issue.</p><p><img vspace="5" hspace="5" src="Step_03_DV_DivByZeroDebug.png" alt=""> </p><p>The cause of the issue is the "holdrate" lower limit value of (0).</p><p>6.  Change the lower limit of "holdrate" in the workspace to (1).</p><p><img vspace="5" hspace="5" src="Step_03_DV_SetLimInWS.png" alt=""> </p><p>Update the <b>Design Verifier</b> settings to include the new range of "holdrate".</p><p>7.  In the <b>Parameters</b> section, select all parameters and press <b>Clear</b>.</p><p>8.  Select <b>Find in Model</b> to populate the parameter table with the new "holdrate" limits from the workspace.  Make sure to uncheck the <b>Use</b> column for "maxtspeed" and "mintspeed".</p><p><img vspace="5" hspace="5" src="Step_03_DV_CfgDivByZeroFixed.png" alt=""> </p><p>9.  Run <b>Design Error Detection</b> on the model</p><p><img vspace="5" hspace="5" src="Step_03_DV_CfgDivByZeroResultsFixed.png" alt=""> </p><h2>Automating Design Error Detection Checks<a name="6"></a></h2><p>What we have shown is an interactive, manual way to run the checks. There is an automated method to run the <b>Design Error Detection</b> checks on the model with <b>Model Advisor</b>.</p><p>1.  Make the menu selection <b>Analysis/Model Advisor/Model Advisor</b></p><p>2.  In the popup window, choose the top model, "CruiseControl" to analyze</p><p><img vspace="5" hspace="5" src="Step_03_DV_MdlAdvCfg.png" alt=""> </p><p>3.  Navigate to <b>Model Advisor/By Task/Simulink Design Verifier Design Error Checks</b>.</p><p>4 Select (2) checks to run: <b>^Detect Dead Logic</b> and <b>^Detect Division By Zero</b></p><p>5.  Press <b>Run Selected Checks</b> for the <b>Design Error Detection</b> group of checks</p><p><img vspace="5" hspace="5" src="Step_03_DV_MdlAdvResults.png" alt=""> </p><p>With the inclusion of <b>Design Error Checks</b> in <b>Model Advisor</b> you now have the option of adding these checks as part of your development and testing workflow.  These checks may be a pre-condition to begin the more formalized testing shown in <b>Step 4: Testing by Simulation</b>.</p><h2>Summary<a name="7"></a></h2><p>With the functions above, we were able check our Cruise Control model for difficult design errors like dead logic and divide by zero.  The analysis was very automated with minimal work to configure the analysis to run on our model.  We utilized the <b>Design Error Detection</b> function of <b>Simulink Design Verifer</b> to find the design errors.</p><p>The <b>Design Error Detection</b> function is based on formal methods which does not require dynamic execution of the model or the creation of test vectors to perform the analysis.  Formal methods use the entire specified range of signals and parameters to prove the absence of design errors. If during the analysis, a design error is found then a test case is generated including the input test vectors and parameter values.  A test harness can also be created to execute the test case to isolate and fix the design issue.</p><p>When the <b>Design Error Detection</b> analysis was performed on our Cruise Control model, two types of design issues were found:  dead logic and divide by zero.  It was easy to analyze the results presented on the model and the generated test harnesses to fix these issues.</p><p>We were able to find and fix these issues early in our development process, increasing confidence in our design.  We will continue to answer more of the questions in the next steps with our structured and formal testing framework for securing the quality, robustness and safety of our cruise controller.</p><p><img vspace="5" hspace="5" src="Step_03_CruiseControl_Summary.png" alt=""> </p><p>When you are finished, close all models and files - <b><a href="matlab:bdclose('all');">click here</a></b>.</p><p>Go to <b>Step 4: Testing by Simulation</b> - <b><a href="Step_04.html">click here</a></b>.</p><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2018b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Step 3: Detecting Design Errors 
%
%% Introduction
%
% <<Step_03_CruiseControl_WhatNow.png>>
%
% There are many different ways to perform testing in Simulink.
% Traditionally, verification involves the user creating a set of test
% vectors based on certain requirements. The user can also create a set of
% expected outputs matching the giving inputs, or visually analyze the
% simulation making sure the behavior is as expected. The type of test
% vector created can be either functional, or based on certain robustness
% criteria or standards. With this method, the quality of the test is
% entirely based on the quality of the input vectors and being able to
% capture or reproduce a real world scenario as closely as possible. This
% topic is covered in *Step 4:  Testing by Simulation*. 
%
% One of the benefits of Model-Based Design is the ability to apply other
% “non-simulation” techniques to your model. These formal techniques are 
% most beneficial when you are working with logic-intensive models. In this
% section, we will use *Simulink Design Verifier* to formally analyze our 
% model for us to check if there are any unreachable states or
% transitions and if there are any divide by zero design errors.  The 
% recommendation is to run these design error checks before executing the 
% simulation based tests to catch errors early and have a more efficient testing 
% workflow.
%
% There are three main functions *Simulink Design Verifier*:
%
% # *Design Error Detection*:  Focus of this step, finds hard to find
% design errors including dead logic, divide by zero, overflow and out of 
% bound array access
% # *Test Generation*: Focus of *Step 5:  Test Case Generation*, generate 
% test cases based on model objectives and/or coverage objectives to
% augment functional test cases
% # *Property Proving*:  Focus of *Step 8:  Property Proving*, model the
% expected behavior and prove the implementation will always meet
% requirements
%
% <<Step_04_SLDVOverview.png>>
%
% In addition to formal techniques for model checking, there are formal
% techniques for code checking.  These methods are similar to the checks
% for the model and we will will perform these checks on the associated 
% code for an s-function block in the model.  We will be using Polyspace 
% Bug Finder to analyze the code for run-time errors including dead 
% code, divide by zero, overflow and out of bound array access.
%
%% Verification and Validation Tools Used
%
% * Simulink Design Verifier
% * Polyspace Bug Finder
%
%% Running Dead Logic Detection on the Model
%
% In this step, we are going to use *Simulink Design Verifier* to analyze our
% model. Our goal is find dead logic, meaning logic that cannot be true and 
% false based on the input ranges and data flow analysis. We can also 
% analyze our model for design errors like integer overflows, division by 
% zero and out of bound array access. 
%
% We will be using *Design Error Detection* to check each design iteration.
% In this section we will first analyze our design from the ad-hoc testing and
% then in a later section iteratively change the design based on feedback 
% from design reviews and field testing.
%
% *_Simulink Design Verifer uses formal methods which
% means that the analysis is "exhaustive" compared to simulation-based
% testing which is "non-exhaustive"._*
%
% We will be using the "CruiseControl" model with the design changes from
% the ad-hoc testing. 
%
% To perform the dead logic analysis, do the following:
%
% 1.  Open "CruiseControl.slx" – *<matlab:B1_DED_IterDesign click here>*.
%
% 2.  Make the menu selection *Analysis/Design Verifier/Options*.
%
% <<Step_03_DV_OptMenu.png>>
%
% 3.  In the *Configuration Parameters* dialog, navigate to ...
% *Design Error Detection*, check *Dead logic*, check *Identify active logic* and select *OK*.
%
% <<Step_03_DV_OptUI.png>>
%
% 4.  To perform the analysis, make the menu selection *Analysis/Design Verifier/Detect Design Errors/Model*.
%
% Once completed the results window will appear. Near the top of the results
% window, there is information that tells the user the current status.  In
% this case, the model has total of (74) objectives. 
%
% <<Step_03_DV_Results1.png>>
% 
% For each decision or transition, there are two objectives: one for a true
% result and one for a false result.  There are also two corresponding 
% objectives for each condition.   As an example, a single condition 
% decision would only have (2) objectives but a double condition decision 
% would have (6) objectives:
%
% * (2) for the decision and 
% * (4) for the two conditions
% 
% *The analysis will shows there are no falsified objectives.*
%
% This means all of the T/F decision and condition objectives *can* be
% achieved based on the input ranges and data flow analysis.  This is a
% static test and should not be confused with coverage analysis which
% indicates whether each objective has been achieved through a dynamic test
% or a simulation test using a set of input vectors.  Below we will show 
% how to get coverage based on the generated test cases from the analysis.
%
% *It is recommended to run Design Error Detection for Dead Logic before 
% simulation based testing and before checking in design changes.*
%
% 5. To review the results on the model, select "Highlight analysis results
% on the model" in the results summary window.  Select transitions in the 
% chart to understand what objectives are being analyzed.  
% 
% In the example below, the exit transition "[Brake || Speed>maxtspeed || Speed<mintspeed]" 
% was analyzed for (2) Decision objectives and (6) Condition Objectives.
%
% <<Step_03_DV_ResultsColors1.png>>
%
% 6.  For more details on the results open the report by selecting the 
% "Detailed analysis report: (HTML)" link in the results summary window.  
%
% To get help with interpreting the *Design Verifier* results in the report - 
% *<matlab:web(fullfile(docroot,'sldv/ug/simulink-design-verifier-reports.html')) click here>*.
%
% The results show all objectives as "Active Logic - needs simulation" which
% means further simulation is needed to confirm the "active logic" status. 
% *Design Verifier* has generated test cases and created a test harness to
% facilitate the confirmation of the "active logic" status.
%
% 7. To open the harness select "Open harness model" in the results summary
% window.
%
% <<Step_03_DV_ResultsHarness1.png>>
%
% 8. Open the "Signal Builder" block in the harness and press the "Run All"
% button.
%
% <<Step_03_DV_ResultsSigBldr1.png>>
%
% Once all the test cases have been executed a "Coverage Results" window 
% will popup to show the coverage results for the harness.  
%
% <<Step_03_DV_ResultsCoverage1.png>>
%
% These are coverage results for running all the generated test cases.  
% Notice the "CruiseControl_harness" has 100% coverage which confirms the 
% "active logic" status for all the objectives.  The generated test cases are
% structural and not functional test cases, meaning they are not based on
% requirements or expected behavior.  This confirms it is possible to
% create requirements based test cases to completely cover the model if the
% requirements and implementation match.  More on this topic is covered in
% "Step 4:  Testing by Simulation".
%
% 9.  Select "Highlight model with coverage results" to show all
% transitions are fully covered.
%
% <<Step_03_DV_HighlightCoverage1.png>>
%
% We now have a good design that has passed ad-hoc testing and has no
% dead logic.
%% Checking Design Changes for Dead Logic
%
% In the previous section we showed our refined model from the ad-hoc 
% testing had no "dead logic" or all "active logic".  In this section we 
% will go through a few design iterations and analyze each change for 
% "dead logic" using *Design Error Detection* function as we did
% in the previous section.
%
% From a design review it was pointed out that the early ad-hoc testing and
% static analysis were performed with nominal calibration values.  It was
% recommended to perform the ad-hoc testing and static analysis at the
% limits of the calibration values.  Specifically test the design with the
% maximum "holdrate" of (10) and the maximum "incdec" of (2).  First an
% "incdec" value of (2) was used; the design passed the ad-hoc testing and
% the static analysis with no "dead logic".  Next a "holdrate" value of
% (10) was used: the design passed the ad-hoc testing and the static 
% analysis found (10) objectives were "dead logic".  Let's modify the
% "holdrate" value to (10) and run *Design Error Detection* to investigate
% the results.
%
% 1.  If not open, open "CruiseControl.slx" – *<matlab:B1_DED_IterDesign click here>*.
%
% 2.  In the command window, execute "holdrate.Value = 10"
%
% <<Step_03_DV_Iter1_holdrate10.png>>
%
% 3.  Perform *Design Error Detection* on the model
%
% <<Step_03_DV_Iter1_Results.png>>
%
% <<Step_03_DV_Iter1_Colors0.png>>
%
% 4.  Analyze the transitions with "dead logic"
%
% <<Step_03_DV_Iter1_Colors1.png>>
%
% * Transition "[after(10*incdec/holdrate,tick)]" can never be false.  The
% transition expression "10*incdec/holdrate" evaluates to (1).  The tick
% value is always greater than or equal to (1) so the transition will
% always be valid (or executed).
%
% <<Step_03_DV_Iter1_Colors2.png>>
%
% * Transition "hasChangedTo(AccelResSw,false) || tspeed>maxtspeed" can
% never be false.  The transition is only tested after the first transition
% "[AccelResSw]" is false so the condition "hasChangedTo(AccelResSw,false)"
% will always be true.  The overall decision will always be true which
% makes the second condition of an or decision "dead logic".
%
% It appears the design has logic errors when we have a "holdrate" of (10).
% But we know that with a "holdrate" of (5) the design has no "dead logic".
% Is there a way to test the design with multiple values of the "holdrate"
% that would show the design has no "dead logic"?  Yes!  *Design Verfier*
% provides a pane to enter a range of parameters to be used in the static
% analysis.
%
% 5.  Open *Design Verifier* and navigate to the "Parameters" section.
% Configure the "Parameters" to use the full range of "[0 10]".  This
% can be automated by selecting *Find in Model* and enabling the *Use* of
% the "holdrate" parameter.
% 
% <<Step_03_DV_ParamTable.png>>
%
% 6.  Run *Design Error Detection* on the model
%
% <<Step_03_DV_Iter1_Results2.png>>
%
% Using the parameter range, *Design Error Detection* now shows our design
% has no "dead logic". 
%
% The model was then analyzed in a design review meeting.  From the design 
% review it was highly recommended to change the execution order of the 
% exit transition and hold transition so the exit condition based on the 
% maximum safe speed was executed first.
%
% 7.  In the model change the execution order so the exit condition based 
% on target speed "tspeed" from the "Accel" and "Coast" state were executed
% first.
%
% <<Step_03_DV_IterModel1.png>>
%
% 8.  Run *Design Error Detection* on the model
%
% <<Step_03_DV_Iter2_Results.png>>
%
% 9.  Analyze the transitions with "dead logic"
%
% <<Step_03_DV_Iter2_Colors1.png>>
%
% * Transition "[AccelResSw]" can never be false.  This transition is now 
% tested after the first transition condition "hasChangedTo(AccelResSw,false)" 
% has been evaluated.  If "hasChangedTo(AccelResSw,false)" is false then
% "[AccelResSw]" has to be true making the false objective for "[AccelResSw]"
% not achievable.
% 
% 10.  Remove the "[AccelResSw]" transition and the corresponding "[CoastSetSw]"
% transition. 
%
% 11. Run *Design Error Detection* on the model
%
% <<Step_03_DV_Iter1_Results2.png>>
%
% Once again we have been able to make design changes and use *Design Error Detection*
% to aid us in achieving a robust design with no "dead logic".
%
% After another design review, it was recommended to include limit checks
% on the speed "Accel" and "Coast" calculation to improve the robustness
% with respect to having the target speed go beyond the safety limits
% "maxtspeed" and "mintspeed".
%
% 12.  Modify the model to include these limit checks on the target speed 
% or load a modifed model – *<matlab:B1_DED_IterDesign3 click here>*.
%
% <<Step_03_DV_IterModel3.png>>
%
% 13.  Run *Design Error Detection* on the model
%
% <<Step_03_DV_Iter3_Results.png>>
%
% 14.  Analyze the transitions with "dead logic"
%
% <<Step_03_DV_Iter3_Colors1.png>>
%
% * Transition condition "tspeed > maxtspeed" can never be true due to the
% limit check in the "Accel" state.  While looking at this condition, is 
% there a design logic error?  Yes!  The transition condition should be
% "tspeed *>=* maxtspeed".
%
% * The corresponding transition "tspeed < mintspeed" for the "Coast"
% state shows "dead logic" and needs to be modified to "tspeed <= mintspeed".
%
% 15.  Modify the model to include these logic operator changes. 
%
% <<Step_03_DV_IterModel3_2.png>>
%
% 16.  Run *Design Error Detection* on the model
%
% <<Step_03_DV_Iter3_Results2.png>>
%
% It might be a suprise that the results show (2) falsified objectives.  
%
% 17.  Analyze the transitions with "dead logic"
%
% <<Step_03_DV_Iter3_Colors2.png>>
%
% The "tspeed" limit transition "[tspeed > maxtspeed]" true objective was
% found to be "dead logic".  The modified exit condition "tspeed >=
% maxtspeed" will exit the state before "tspeed" can be increased beyond
% "maxtspeed".  Based on this result, maybe the recommended safety design
% change was not needed.  With further study, we realize the value of 
% "incdec" was (1) for the static analysis but in practice it can have a 
% value of (1) or (2).  For an "incdec" value of (2) it appears the limit 
% check is necessary.  Let's include the range of "incdec" in the analysis.
%
% 18.  Modify the *Design Verifier* settings to include the range of
% "incdec"
% 
% <<Step_03_DV_ParamTable2.png>>
%
% 19.  Run *Design Error Detection* on the model
%
% <<Step_03_DV_Iter3_Results3.png>>
%
% 20.  In the model select the transition "[tspeed > maxtspeed]" to update
% the results window.  To retrieve the "Test #", select *View test case* to
% open up the signal builder dialog with "Test Case 9" displayed.
%
% <<Step_03_DV_Iter3_Transition.png>>
%
% 21.  Use the test # (9) to navigate to the "Test Case 9" in the report 
% that satisfies the true objective for the "[tspeed > maxtspeed]" 
% transition in the limit check.
%
% <<Step_03_DV_Iter3_TestCaseRpt3.png>>
%
% Notice the test case uses a value of (2) for "incdec".
%
% We have gained an insight into our design by iteratively checking our 
% design and interpreting the results.
%% Running Divide by Zero Detection on the Model
%
% Another feature of *Design Error Detection* is the ability to
% analyze the model for calculations that result in a divide by zero.  
% Calibrations typically have a range of values that are permissible within
% specified limits. As we did in the previous section, we will use the 
% parameter table in the *Simulink Design Verifier* settings to perform 
% the analysis over a range of values.  To perform the "divide by zero" 
% analysis, do the following:
%
% 1.  Open the "CruiseControl.slx" based on the "dead logic" work – 
% *<matlab:B2_DED_DivideByZero; click here>*.
%
% 2.  In the *Design Verifier* settings, check the parameter table has been
% enabled with "holdrate" and "incdec" enabled.  These are the same 
% settings from the final "dead logic" analysis perform in the previous 
% section.
%
% <<Step_03_DV_ParamTable2.png>>
%
% 2.  For this analysis, configure *Design Error Detection* to check for 
% *Division by zero*.
%
% <<Step_03_DV_CfgDivByZero.png>>
%
% 3.  Make the menu selection *Analysis/Design Verifier/Detect Design Errors/Model*
% to perform the analysis on the model
%
% <<Step_03_DV_DivByZeroResult1.png>>
%
% Let’s take a look at the results and see what might be causing the error.
%
% 4.  Open the report to help us debug the divide by 
% zero issue.
%
% <<Step_03_DV_DivByZeroReport.png>>
%
% Since the analysis included the use of a parameter table to specify a
% range of parameter values that were part of the analysis.  Navigate in 
% the report to the "Parameter Constraints" section to verify the range 
% that was used in the analysis.  Next look at the generated test cases, 
% noting the parameter values of (0) for the "holdrate". 
%
% 5.  Using the generated harness model, run "Test Case 1" to debug the issue.
%
% <<Step_03_DV_DivByZeroDebug.png>>
%
% The cause of the issue is the "holdrate" lower limit value of (0).
%
% 6.  Change the lower limit of "holdrate" in the workspace to (1).  
% 
% <<Step_03_DV_SetLimInWS.png>>
%
% Update the *Design Verifier* settings to include the new range of
% "holdrate".  
%
% 7.  In the *Parameters* section, select all parameters and press
% *Clear*. 
%
% 8.  Select *Find in Model* to populate the parameter table with the
% new "holdrate" limits from the workspace.  Make sure to uncheck the 
% *Use* column for "maxtspeed" and "mintspeed". 
%
% <<Step_03_DV_CfgDivByZeroFixed.png>>
%
% 9.  Run *Design Error Detection* on the model
%
% <<Step_03_DV_CfgDivByZeroResultsFixed.png>>
%
%% Automating Design Error Detection Checks
%
% What we have shown is an interactive, manual way to run the checks.  
% There is an automated method to run the *Design Error Detection* checks
% on the model with *Model Advisor*.
%
% 1.  Make the menu selection *Analysis/Model Advisor/Model Advisor*
%
% 2.  In the popup window, choose the top model, "CruiseControl" to
% analyze 
%
% <<Step_03_DV_MdlAdvCfg.png>>
%
% 3.  Navigate to *Model Advisor/By Task/Simulink Design Verifier Design Error Checks*.
%
% 4 Select (2) checks to run: *^Detect Dead Logic* and *^Detect Division By
% Zero*
%
% 5.  Press *Run Selected Checks* for the *Design Error Detection* group of
% checks
%
% <<Step_03_DV_MdlAdvResults.png>>
%
% With the inclusion of *Design Error Checks* in *Model Advisor* you now
% have the option of adding these checks as part of your development and 
% testing workflow.  These checks may be a pre-condition to begin the more
% formalized testing shown in *Step 4: Testing by Simulation*.
%% Summary
%
% With the functions above, we were able check our Cruise Control model 
% for difficult design errors like dead logic and divide by zero.  The 
% analysis was very automated with minimal work to configure the analysis
% to run on our model.  We utilized the *Design Error Detection* function 
% of *Simulink Design Verifer* to find the design errors.    
%
% The *Design Error Detection* function is based on formal methods which 
% does not require dynamic execution of the model or the creation of test 
% vectors to perform the analysis.  Formal methods use the entire specified
% range of signals and parameters to prove the absence of design errors.
% If during the analysis, a design error is found then a test case is 
% generated including the input test vectors and parameter values.  A test 
% harness can also be created to execute the test case to isolate and fix 
% the design issue.  
%
% When the *Design Error Detection* analysis was performed on our Cruise 
% Control model, two types of design issues were found:  dead logic and 
% divide by zero.  It was easy to analyze the results presented on the model
% and the generated test harnesses to fix these issues.  
%
% We were able to find and fix these issues early in our 
% development process, increasing confidence in our design.  We will 
% continue to answer more of the questions in the next steps with our 
% structured and formal testing framework for securing the quality, 
% robustness and safety of our cruise controller.    
%
% <<Step_03_CruiseControl_Summary.png>>
%
% When you are finished, close all models and files -
% *<matlab:bdclose('all'); click here>*.
%
% Go to *Step 4: Testing by Simulation* - *<Step_04.html click here>*.
%
##### SOURCE END #####
--></body></html>